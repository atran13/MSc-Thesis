\section{Results}
\label{sec:results}

\subsection{Scene text detection}
\label{subsec:result1}
Some example signage instances per class can be seen in Figure \ref{fig:instance_ex}.

{
\setlength\intextsep{7pt}
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{media/results/instances/instance_gen.jpg}
    \caption{Gentrified}
\end{subfigure}
\quad
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{media/results/instances/instance_non.jpg}
    \caption{Non-gentrified}
\end{subfigure}
\caption{Signage instances examples.}
\label{fig:instance_ex}
\end{figure}
}

It was found that the text detection model returned almost all signage instances present in the original street view images, including signage with non-horizontal and curved text. Cases where the model failed include very small, and therefore illegible texts, especially in lower resolution images. Additionally, the model also returned some noise, namely texts on street signs (e.g. traffic signs, street names), and watermarks ("©Google", as the images in Street-Swipe were originally from Google Street View) - these instances were manually removed.


\subsection{Classification}
\subsubsection{Baseline}
Test set results of the baseline model are shown in Table \ref{fig:baseline_metrics}. 

% {
% \setlength\intextsep{7pt}
\begin{table}[h]
\begin{tabular}{llcc}
\toprule
\multirow{2}{*}{Metrics}   & \multirow{2}{*}{Class} & \multicolumn{2}{c}{Baseline model}        \\ \cline{3-4} 
                           &                        & Classwise & Average                 \\ \hline
Accuracy                   & Gentrified             & 0.2143    & \multirow{2}{*}{0.5810} \\
                           & Non-gentrified         & 0.9478    &                         \\
Precision                  & Gentrified             & 0.6122    & \multirow{2}{*}{0.6852} \\
                           & Non-gentrified         & 0.7582    &                         \\
Recall                     & Gentrified             & 0.2143    & \multirow{2}{*}{0.5810} \\
                           & Non-gentrified         & 0.9478    &                         \\
F1-score                   & Gentrified             & 0.3175    & \multirow{2}{*}{0.5800} \\
                           & Non-gentrified         & 0.8425    &                         \\
\bottomrule
\end{tabular}
\vspace{\baselineskip}
\caption{Classwise and macro-averaged test set metrics of baseline model (ResNet50, no weighted sampling, no fine-tuning). This model achieved very high performance for non-gentrified signage, but performed poorly on gentrified signage, due to class imbalance.}
\label{fig:baseline_metrics}
\vspace{-5mm}
\end{table}
% }

\subsubsection{Fine-tuned}
The best performing model with ResNet18 architecture was found with learning rate set to 0.001, batch size 32, and 60 training epochs. The best performing model with ResNet50 architecture was found with learning rate set to 0.01, batch size 64, and 60 training epochs. The macro-averaged metrics for these models on the validation and test sets are shown in Table \ref{fig:resnet_compare}. The fine-tuned ResNet50 had better performance, its classwise metrics are shown in Table \ref{fig:resnet50_cls}.

% {
% \setlength\intextsep{10pt}
\begin{table}[h!]
    \begin{tabular}{lcccc}
    \toprule
\multirow{2}{*}{Metrics} & \multicolumn{2}{c}{ResNet18} & \multicolumn{2}{c}{ResNet50} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5}
                         & Val           & Test          & Val           & Test         \\ \hline
Accuracy                 & 0.6497        & 0.6960        & 0.6506        & \textbf{0.7033}       \\
Precision                & 0.6185        & 0.6715        & 0.6209        & \textbf{0.6795}       \\
Recall                   & 0.6497        & 0.6960        & 0.6506        & \textbf{0.7033}       \\
F1-score                 & 0.6222        & 0.6781        & 0.6256        & \textbf{0.6865}       \\ \bottomrule
    \end{tabular}
    \vspace{\baselineskip}
    \caption{Macro-averaged metrics of fine-tuned ResNet18 and ResNet50 on the validation and test set. Between these two models, the fine-tuned ResNet50 performed better.}
    \label{fig:resnet_compare}
    \vspace{-5mm}
\end{table}
% }

% {
% \setlength\intextsep{0pt}
\begin{table}[h!]
\begin{tabular}{llcc}
\toprule
\multirow{2}{*}{Metrics}   & \multirow{2}{*}{Class} & \multicolumn{2}{c}{ResNet50} \\ \cline{3-4} 
                           &                        & Val           & Test         \\ \hline
Accuracy                   & Gentrified             & 0.5714        & 0.6429       \\
                           & Non-gentrified         & 0.7299        & 0.7637       \\
Precision                  & Gentrified             & 0.3953        & 0.5114       \\
                           & Non-gentrified         & 0.8464        & 0.8476       \\
Recall                     & Gentrified             & 0.5714        & 0.6429       \\
                           & Non-gentrified         & 0.7299        & 0.7637       \\
F1-score                   & Gentrified             & 0.4674        & \textbf{0.5696}       \\
                           & Non-gentrified         & 0.7838        & \textbf{0.8035}       \\
\bottomrule
\end{tabular}
\vspace{\baselineskip}
\caption{Classwise metrics of the best model. Even though there was an improvement in classifying gentrified signage compared to the baseline model, this model still performed better for non-gentrified signage, as shown in the F1-scores of each class.}
\label{fig:resnet50_cls}
\vspace{-7mm}
\end{table}
% }

\subsection{Testing on the extended data}
The average and classwise metrics of the best model in classifying the extended data are presented in Table \ref{fig:resnet50_pano}.

% {
% \setlength\intextsep{2.65pt}
\begin{table}[h!]
\begin{tabular}{llcc}
\toprule
\multirow{2}{*}{Metrics}   & \multirow{2}{*}{Class} & \multicolumn{2}{c}{ResNet50}   \\ \cline{3-4} 
                           &                        & Classwise & Average                 \\ \hline
Accuracy                   & Gentrified             & 0.5340    & \multirow{2}{*}{0.5807} \\
                           & Non-gentrified         & 0.6274    &                         \\
Precision                  & Gentrified             & 0.7359    & \multirow{2}{*}{0.5725} \\
                           & Non-gentrified         & 0.4092    &                         \\
Recall                     & Gentrified             & 0.5340    & \multirow{2}{*}{0.5807} \\
                           & Non-gentrified         & 0.6274    &                         \\
F1-score                   & Gentrified             & 0.6189    & \multirow{2}{*}{0.5571} \\
                           & Non-gentrified         & 0.4953    &                         \\
\bottomrule
\end{tabular}
\vspace{\baselineskip}
\caption{Macro-averaged and classwise metrics of the best model on the extended data. Compared to the metrics on StreetSwipe's test set (Table \ref{fig:resnet_compare}), there was a decrease of approximately 10\% in all average metrics.}
\label{fig:resnet50_pano}
\vspace{-7mm}
\end{table}
% }

\subsection{Inspecting model's output}
\label{subsec:result4}

\subsubsection{Correct classifications}

StreetSwipe's correctly classified signage showed the most typical and distinguishing characteristics of signage per class, which can be seen in Figure \ref{fig:output_vis}.

Gentrified signage were more similar in font types (more modern and minimal fonts) and often did not vary in text sizes, while non-gentrified signage used more types of fonts (more classic and decorated fonts), sometimes more than one font on a single sign, and sometimes with varying text sizes and orientations. In addition, gentrified signs mostly had white texts, with minimal variation in background colors. Non-gentrified signs were the opposite: text colors and background colors varied more; plus a notable usage of neon signage. In terms of languages, besides Dutch, gentrified signage had more English text, with very rare appearances of non-Latin languages (e.g. Korean); while non-gentrified ones were largely in Dutch, with appearances of English, Chinese and Arabic. And finally, although out of scope of the study, the model also picked up graffiti as text instances belonging to non-gentrified facades.


\subsubsection{Incorrect classifications} 

StreetSwipe's misclassified signage showed characteristics of cases the model failed to distinguish. The misclassified instances with high certainty showed similar characteristics to correctly classified instances (gentrified: minimal text fonts and colors, less variation in font styles and background colors; non-gentrified: more variation in fonts, text colors and background colors). On the other hand, mis-classified instances with lower certainty showed a more nuanced picture. Signal strength diminished and the model's outputs of the two classes were more or less indistinguishable. There were similar variations in font styles, text colors and background colors, without any characteristic that stood out. Results can be seen in Figure \ref{fig:output_vis_SS_incorrect}.


\subsubsection{Classifications on extended data}

On the extended data, signage classified by the model followed the same patterns per class as learned from StreetSwipe; however, visual inspection of the corresponding facades showed not all classifications were true to human perception. Results can be seen in Figure \ref{fig:output_vis_pano}.

% {
% \setlength{\floatsep}{0pt}
\begin{figure*}[hbtp]
    \centering
    \includegraphics[width=\textwidth]{media/results/output_vis-SS_correct1.jpg}
        \caption{StreetSwipe's correctly classified signage per class with probability of 80\% and above. Note how non-gentrified signage varied more in their characteristics (more font types, colors, and languages) while gentrified signage appeared more homogenized.}
        \label{fig:output_vis}
    \vspace{0.5cm}
    \includegraphics[width=0.8\textwidth]{media/results/output_vis-SS_incorrect.jpg}
        \caption{StreetSwipe's misclassified signage per class, grouped by high and low classification certainty. Incorrect classifications with high certainty from both classes generally had the same characteristics as correctly classified instances. As classification certainty decreased, variations in fonts and colors were no longer distinctive across the two classes.}
        \label{fig:output_vis_SS_incorrect}
    \vspace{0.6cm}
    \includegraphics[width=\textwidth]{media/results/output_vis_pano.jpg}
        \caption{Model's classifications on the extended data's signage with classification probability of 80\% and above (disregarding ground truth label). While the model classified signage based on the same typical class characteristics as in StreetSwipe, classifications were not always plausible: Bánh Mì Deli (left) and Personality (right) were gentrified-looking facades, but Personality was misclassified as non-gentrified via its signage.}
        \label{fig:output_vis_pano}
\end{figure*}
% }
