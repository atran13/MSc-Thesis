\newpage
\section{Discussion}
\label{sec:discussion}
% Compare your results with the state-of-the-art and reflect upon the results and limitations of the study. You can already hint at future work to which you come back in the conclusion section.
% Write your discussion here. Do not forget to use sub-sections. Normally, the discussion starts with comparing your results to other studies as precisely as possible. The limitations should be reflected upon in terms such as reproducibility,  scalability,  generalizability,  reliability  and  validity. It is also important to mention ethical concerns.


\subsection{Summarizing results}

In using a fine-tuned ResNet50, the current study was able to find the same patterns of gentrification in storefront signage aesthetics as previous research \cite{rahman_signage_2020, trinch_signsays_2017, snajdr_oldschool_2018, snajdr_preserve_2022}. These patterns were that: gentrified signage appeared more homogenized, with a large proportion having white text on dark background colors, and less variation in font styles and color usage as compared to non-gentrified signage. Non-gentrified signage largely had brighter colors on both the text and the background, and also were more likely to use a combination of font styles and colors in the same sign. Additionally, neon signage were much more prevalent in non-gentrified facades; and - while not signage - graffiti instances were recognized as another common textual feature of this class. In terms of languages, English was found to be a common language among gentrified signage, seemingly replacing the Dutch local language found largely in non-gentrified signs. This pattern was the same as the case of Phnom Penh \cite{kasanga_map_2012}. Furthermore, non-gentrified signs had many instances in Chinese, Arabic, and some in English - a pattern also found in New York \cite{trinch_signsays_2017}.

Using a image classification model had also enabled the current study to make conclusions on fuzzy cases, via inspecting the model's mis-classified instances. These were instances where gentrified-labeled signs actually had the defining characteristics of non-gentrified signs, and thus were identified as such by the model with high certainty. Further, as classification certainty decreased, we were able to see signage with characteristics untypical of any class. Findings were that mis-classified signage with high certainty showed the same characteristics of the class they were assigned to. As classification certainty decreased, so did the distinctiveness between the two classes: variations in fonts and colors were no longer differentiating one class from another. Such output showed more nuances in identifying gentrification via signage. Signage could not always tell the full story based on visual alone, as signage of non-gentrified facades can still appear gentrified and vice versa, with strong and consistent visual signals found by the model. Especially for the cases of lower classification certainty, the model failed to tell apart gentrified from non-gentrified signs as signals from both classes appeared together. While we were able to see what signs looked like  beyond the most typical cases of (non-)gentrification - something previous studies did not point out - ultimately these are the cases where the model failed to distinguish. 


Utilizing street view imagery and computer vision had also enabled this study to overcome the limitations of past research. Past studies, in using labor-intensive manual data collection and qualitative methods, could only make conclusions on a neighborhood scale \cite{reades_understanding_2019, barton_exploration_2016}. By using StreetSwipe's crowdsourced street view data, the signage aesthetics learned in this study were not only on a city-wide scale, but also were based on the common perception of a wide audience.

3. There is a gap between the model's performance on StreetSwipe and on extended data of other gentrified/non-gentrified neighborhoods. This suggests that "statistically" gentrified does not necessarily mean visually gentrified. This points to question about the neighborhood's demographic makeup. It could be the case that displacement did not happen to old residents, or it did happen but old business owners were able to cater to new residents and remained in the gentrified neighborhoods.

4. Characteristics of signage as classified by the model are in-line with findings of previous research: gentrified signage looks more homogenized, and are more likely to be in English, while non-gentrified signs look more decorated with serif fonts and more colors, and are largely in Dutch, with more appearances of other languages.

5. Misclassified signage with high certainty followed the styles of the class they were classified to (i.e. non-gentrified signage could have minimalist use of fonts and colors, which made them appear gentrified). 

6. Signage of the extended dataset follow the style of the class they were classified to (they look like the correctly classified instances from StreetSwipe). Suggests model is generalizable to detect gentrification through signage, based on visual perception.

\subsection{Limitations}
\subsubsection{Data-related limitations}

- StreetSwipe limitations: (1) Number of votes in pre-july 2020 version is lacking, could lead to lower reliability of results, (2) Class imbalance, (3) Varying dates of the data (dates back to 2009 approx) - while we technically could still learn perception as the images were human-annotated, the results shouldn't be interpreted as fully representing the most up-to-date state of gentrification in Amsterdam.

- Extended data: Text instances generally had much lower resolutions compared to StreetSwipe (bc images were taken from a further distance), therefore could have contributed to model's worsened performance.

\subsubsection{Methodology-related limitations}

- Class imbalance led to model's lower performance on gentrified signage compared to non-gentrified.

- Cropping out text instances loses contextual info: where the text are placed (windows or above the stores' entrances, or standees, posters etc.), text density on signage, numbers of font types and colors used, whether a combination of signage types (above entrance, on window, standee) was used, what the rest of the buildings look like, what else appear in the store facade other than signage (e.g. window displays)

- Traditional qualitative studies are able to go into extensive semantic details and point out all the nuances. E.g. given incorrect classifications in our case: can't tell the full story based on visual alone, signage of non-gentrified facades can still appear gentrified and vice versa, with consistent visual patterns found. The difference must lie in e.g. types of business, locations, and other features of the facade. Such subjective reasonings could be included via using StreetSwipe's mismatch responses, but there was not enough of these to be incorporated into a deep learning model (only 900 responses), plus many were unreliable responses (e.g. respondents putting "X" instead of an actual answer, presumably to be able to skip forward).
